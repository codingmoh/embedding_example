{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all libs\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFLLl1Agum8O"
   },
   "source": [
    "# GPT4 with Retrieval Augmentation over Web\n",
    "\n",
    "In this notebook we'll work through an example of using GPT-4 with retrieval augmentation to answer questions about NOUS Wissensmanagement GmbH.\n",
    "\n",
    "In this example, we will download all the content from https://www.nousdigital.net/en/. \n",
    "\n",
    "This downloads all HTML into the `nous` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xo9gYhGPr_DQ",
    "outputId": "7c4f766c-e70d-41c1-ace6-c1a4f10d9d12"
   },
   "outputs": [],
   "source": [
    "# crawl website content using wget\n",
    "!wget -e robots=off -r -A.html -P nous https://www.nousdigital.net/en/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKOV-6N4vaRl"
   },
   "source": [
    "Now we can use LangChain itself to process these docs. \n",
    "We do this using the `DirectoryLoader` together with the `BSHTMLLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n40_0MtlsKgM",
    "outputId": "ac43dcec-83ec-4b79-e1e1-e82d4418daf8"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import BSHTMLLoader, DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('nous/www.nousdigital.net/en', loader_cls=BSHTMLLoader)\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahFEI4U3vdxV"
   },
   "source": [
    "This leaves us with `232` processed doc pages. Let's take a look at the format each one contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJuef8z1vfz4",
    "outputId": "b760063f-08bd-4afe-afa8-e8a6ab0742ef"
   },
   "outputs": [],
   "source": [
    "docs[20].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove '\\n' in docs.page_content\n",
    "docs[20].page_content = docs[20].page_content.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouY4rcx7z2oa"
   },
   "source": [
    "Now let's see how we can process all of these. We will chunk everything into ~500 token chunks, we can do this easily with `langchain` and `tiktoken`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Rb7KxUqYzsuV",
    "outputId": "50bc3849-e32e-4156-a0c0-5a9f85a4019d"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer_name = tiktoken.encoding_for_model('gpt-4')\n",
    "tokenizer_name.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N635Sgsbx_ME"
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(tokenizer_name.name)\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKO8e3Dp0dQS"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLdvW8eq06Zd"
   },
   "source": [
    "Process the `docs` into more chunks using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "16de7ce25ba244fda60224d6f1692819",
      "521d1e60f0b443b599409b368d8d48a4",
      "8beb4f329e384b2c8249f765e9fa309c",
      "e4c05e745840465793b2aa6db5d8c7a7",
      "931df41ac3104f018715a17a8fbe9a48",
      "8d9454b73ef041a882b3d139e86610b3",
      "346d2a4ab66540d8aabe0eefbc8fd94c",
      "20a64b852cfa4da283032248d498bc03",
      "c28e8e55552a47fcbe147d1b57d249f9",
      "c008a3c306ec4abfad63ede5f50aab12",
      "c90b1375e39e44598830891c0ed8eb0a"
     ]
    },
    "id": "uOdPyiAQ0uWs",
    "outputId": "87c046d1-acf2-410c-f93e-0ac3af627be8"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, page in enumerate(tqdm(docs)):\n",
    "    content = page.page_content\n",
    "    if len(content) > 100:\n",
    "        url = page.metadata['source'].replace('rtdocs/', 'https://')\n",
    "        texts = text_splitter.split_text(content)\n",
    "        chunks.extend([{\n",
    "            'id': str(uuid4()),\n",
    "            'text': texts[i],\n",
    "            'chunk': i,\n",
    "            'url': url\n",
    "        } for i in range(len(texts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JegURaAg2PuN"
   },
   "source": [
    "Our chunks are ready so now we move onto embedding and indexing everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGIZbQqJ2WBh"
   },
   "source": [
    "## Initialize Embedding Model\n",
    "\n",
    "We use `text-embedding-ada-002` as the embedding model. We can embed text like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0U9_7Fium8u",
    "outputId": "ddfb93e8-db19-478e-e6e4-a2aa8657fd88",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7ffb54314720> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"whisper-1\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-internal\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"babbage\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"davinci\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-davinci-edit-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"babbage-code-search-code\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-similarity-babbage-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"gpt-3.5-turbo\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"code-davinci-edit-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-davinci-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"ada\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"babbage-code-search-text\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"babbage-similarity\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"code-search-babbage-text-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-curie-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"code-search-babbage-code-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-ada-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-similarity-ada-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"curie-instruct-beta\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"ada-code-search-code\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"ada-similarity\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"code-search-ada-text-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-ada-query-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"davinci-search-document\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"ada-code-search-text\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-ada-doc-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"davinci-instruct-beta\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-similarity-curie-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"code-search-ada-code-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"ada-search-query\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-davinci-query-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"curie-search-query\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"davinci-search-query\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"babbage-search-document\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"ada-search-document\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-curie-query-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-babbage-doc-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"curie-search-document\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-curie-doc-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"babbage-search-query\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-babbage-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-davinci-doc-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-internal\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-search-babbage-query-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"curie-similarity\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"gpt-4-0314\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"curie\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"gpt-4\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-similarity-davinci-001\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-davinci-002\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"text-davinci-003\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-internal\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"davinci-similarity\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai-dev\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"engine\",\n",
       "      \"id\": \"gpt-3.5-turbo-0301\",\n",
       "      \"ready\": true,\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"created\": null\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\"\n",
    "\n",
    "openai.Engine.list()  # verify that we are authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kteZ69Z5M55S"
   },
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNZ7IWekNLbu"
   },
   "source": [
    "In the response `res` we will find a JSON-like object containing our new embeddings within the `'data'` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esagZj6iNLPZ",
    "outputId": "8108cf02-47d0-4735-8e9f-bb01203ec7b5"
   },
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zStnHFpkNVIU"
   },
   "source": [
    "Inside `'data'` we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains `1536` dimensions (the output dimensionality of the `text-embedding-ada-002` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVoP9VcINWAC",
    "outputId": "38e7cd59-4827-43e9-df99-7a34cff44efc"
   },
   "outputs": [],
   "source": [
    "len(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-zraDCjNeC6",
    "outputId": "354f3093-f75e-47a9-fd57-a2e5b6825ec6"
   },
   "outputs": [],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPd41MjANhmp"
   },
   "source": [
    "We will apply this same embedding logic to the langchain docs dataset we've just scraped. But before doing so we must create a place to store the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPi4MZvMNvUH"
   },
   "source": [
    "## Initializing the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5RRQArrN2lN"
   },
   "source": [
    "Now we need a place to store these embeddings and enable a efficient vector search through them all. To do that we use Pinecone, we can get a [free API key](https://app.pinecone.io/) and enter it below where we will initialize our connection to Pinecone and create a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZO5_EdUAum8v",
    "outputId": "ff535767-f11b-4c42-9fe0-6a2a93e72cb8"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# setup pinecone account to get credentials\n",
    "PINECONE_API_KEY=  os.getenv('PINECONE_API_KEY') or 'PINECONE_API_KEY'\n",
    "PINECONE_ENVIRONMENT='us-west1-gcp-free'\n",
    "\n",
    "os.environ['PINECONE_ENVIRONMENT'] = PINECONE_ENVIRONMENT\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, enviroment=PINECONE_ENVIRONMENT)\n",
    "pinecone.whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GQAnohhum8v",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "index_name = 'gpt-4-nous-docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EO8sbJFZNyIZ",
    "outputId": "dba11498-c8ae-446d-efcc-849698cb7020"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezSTzN2rPa2o"
   },
   "source": [
    "We can see the index is currently empty with a `total_vector_count` of `0`. We can begin populating it with OpenAI `text-embedding-ada-002` built embeddings like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Embedding.create(input=chunks[1]['text'], engine=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f0fc6683ac9745a6a6b05a7eda79d7ff",
      "38caf0a7b4d349aea05fa64c33d05827",
      "406139f96eb94c31898790c0228c8137",
      "e31b9bcceddd4268afac17827d14ba9c",
      "cdf15893692848a59f4af1a968ba6e6b",
      "9b9503b6ca35489faa63b2c3c9d58340",
      "f63cf87fcf8f4b30a55ee0b2474d17b0",
      "f4421e1c005049e1891c359565cec49f",
      "f8ad1c7da79e47e08c67091ffe176340",
      "c8c3bee2c1394f7592f9c9dd3f7410e9",
      "07dc41bf666944af95effceb5f212aa4"
     ]
    },
    "id": "iZbFbulAPeop",
    "outputId": "481a633b-5e9f-449a-dba0-6b82775d27ec"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'url': x['url']\n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YttJOrEtQIF9"
   },
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieval and then answer generation using GPT-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FumVmMRlQQ7w"
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLRODeL-QTJ9"
   },
   "source": [
    "To search through our documents we first need to create a query vector `xq`. Using `xq` we will retrieve the most relevant chunks from the LangChain docs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(query):\n",
    "    return openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "def query_pinecone_embedding(openai_embedding):\n",
    "    # retrieve from Pinecone\n",
    "    xq = openai_embedding['data'][0]['embedding']\n",
    "    # get relevant contexts (including the questions)\n",
    "    return index.query(xq, top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMUPdX9cQQYC"
   },
   "outputs": [],
   "source": [
    "query = \"Who is the CEO of NOUS Wissensmanagement GmbH?\"\n",
    "\n",
    "embedding = create_embedding(query)\n",
    "result = query_pinecone_embedding(embedding)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoBSiDLIUADZ"
   },
   "source": [
    "With retrieval complete, we move on to feeding these into GPT-4 to produce answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfzS4-6-UXgX"
   },
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPC1jQaKUcy0"
   },
   "source": [
    "GPT-4 is currently accessed via the `ChatCompletions` endpoint of OpenAI. To add the information we retrieved into the model, we need to pass it into our user prompts *alongside* our original query. We can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unZstoHNUHeG"
   },
   "outputs": [],
   "source": [
    "def pinecone_to_list(res):\n",
    "    # get list of retrieved texts\n",
    "    contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "    return \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query\n",
    "\n",
    "pinecone_to_list(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sihH_GMiV5_p"
   },
   "source": [
    "Now we configure following prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt(prompt, message, model=\"gpt-4\"):\n",
    "     return openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IThBqBi8V70d"
   },
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "prompt = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
    "user questions based on the information provided by the user above\n",
    "each question. If the information can not be found in the information\n",
    "provided by the user you truthfully say \"I don't know\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(query, model=\"gpt-4\"):\n",
    "    embedding = create_embedding(query)\n",
    "    result = query_pinecone_embedding(embedding)\n",
    "    open_ai_message = pinecone_to_list(result)\n",
    "    return query_gpt(prompt, open_ai_message, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What services does NOUS provide?\"\n",
    "# \"What can you tell me about the company NOUS?\"\n",
    "# \"What services does NOUS provide?\"\n",
    "# \"Who are the CEOs?\"\n",
    "# \"Who runs the company?\"\n",
    "# \"Who is the CEO of NOUS Wissensmanagement?\"\n",
    "# \"How does iteratec talk about digital champions?\n",
    "# \"What services does NOUS Wissensmanagement provide?\"\n",
    "# \"Which technologies does iteratec use?\"\n",
    "\n",
    "result = search_docs(query, model=\"gpt-4\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvS1yJhOWpiJ"
   },
   "source": [
    "To display this response nicely, we will display it in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "RDo2qeMHWto1",
    "outputId": "410faf26-6a5d-4cc9-a21e-1e109af90778"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(result['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ-a8MHg0eYQ"
   },
   "source": [
    "Let's compare this to a non-augmented query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "vwhaSgdF0ZDX",
    "outputId": "8e961096-5182-4852-bc85-dfc7b4038b41"
   },
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CSsA-dW0m_P"
   },
   "source": [
    "If we drop the `\"I don't know\"` part of the `primer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "Z3svdTCZ0iJ2",
    "outputId": "16a91a2a-162a-445b-92ec-c1b5be143991"
   },
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcGon5672lBb"
   },
   "source": [
    "Then we see something even worse than `\"I don't know\"` — hallucinations. Clearly augmenting our queries with additional context can make a huge difference to the performance of our system.\n",
    "\n",
    "Great, we've seen how to augment GPT-4 with semantic search to allow us to answer LangChain specific queries.\n",
    "\n",
    "Once you're finished, we delete the index to save resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah_vfEHV2khx"
   },
   "outputs": [],
   "source": [
    "#pinecone.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07dc41bf666944af95effceb5f212aa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16de7ce25ba244fda60224d6f1692819": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_521d1e60f0b443b599409b368d8d48a4",
       "IPY_MODEL_8beb4f329e384b2c8249f765e9fa309c",
       "IPY_MODEL_e4c05e745840465793b2aa6db5d8c7a7"
      ],
      "layout": "IPY_MODEL_931df41ac3104f018715a17a8fbe9a48"
     }
    },
    "20a64b852cfa4da283032248d498bc03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "346d2a4ab66540d8aabe0eefbc8fd94c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38caf0a7b4d349aea05fa64c33d05827": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b9503b6ca35489faa63b2c3c9d58340",
      "placeholder": "​",
      "style": "IPY_MODEL_f63cf87fcf8f4b30a55ee0b2474d17b0",
      "value": "100%"
     }
    },
    "406139f96eb94c31898790c0228c8137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4421e1c005049e1891c359565cec49f",
      "max": 34,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8ad1c7da79e47e08c67091ffe176340",
      "value": 34
     }
    },
    "521d1e60f0b443b599409b368d8d48a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d9454b73ef041a882b3d139e86610b3",
      "placeholder": "​",
      "style": "IPY_MODEL_346d2a4ab66540d8aabe0eefbc8fd94c",
      "value": "100%"
     }
    },
    "8beb4f329e384b2c8249f765e9fa309c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20a64b852cfa4da283032248d498bc03",
      "max": 891,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c28e8e55552a47fcbe147d1b57d249f9",
      "value": 891
     }
    },
    "8d9454b73ef041a882b3d139e86610b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "931df41ac3104f018715a17a8fbe9a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9503b6ca35489faa63b2c3c9d58340": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c008a3c306ec4abfad63ede5f50aab12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c28e8e55552a47fcbe147d1b57d249f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c8c3bee2c1394f7592f9c9dd3f7410e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c90b1375e39e44598830891c0ed8eb0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdf15893692848a59f4af1a968ba6e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e31b9bcceddd4268afac17827d14ba9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8c3bee2c1394f7592f9c9dd3f7410e9",
      "placeholder": "​",
      "style": "IPY_MODEL_07dc41bf666944af95effceb5f212aa4",
      "value": " 34/34 [00:53&lt;00:00,  1.03it/s]"
     }
    },
    "e4c05e745840465793b2aa6db5d8c7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c008a3c306ec4abfad63ede5f50aab12",
      "placeholder": "​",
      "style": "IPY_MODEL_c90b1375e39e44598830891c0ed8eb0a",
      "value": " 891/891 [00:06&lt;00:00, 127.00it/s]"
     }
    },
    "f0fc6683ac9745a6a6b05a7eda79d7ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38caf0a7b4d349aea05fa64c33d05827",
       "IPY_MODEL_406139f96eb94c31898790c0228c8137",
       "IPY_MODEL_e31b9bcceddd4268afac17827d14ba9c"
      ],
      "layout": "IPY_MODEL_cdf15893692848a59f4af1a968ba6e6b"
     }
    },
    "f4421e1c005049e1891c359565cec49f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f63cf87fcf8f4b30a55ee0b2474d17b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8ad1c7da79e47e08c67091ffe176340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
